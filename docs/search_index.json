[
["index.html", "Time Series Preface", " Time Series Luke Le 2021-10-01 Preface A summary note of Time Series Fundamentals https://bookdown.org/gary_a_napier/time_series_lecture_notes/ChapterOne.html "],
["chapter-1-time-series-fundamentals.html", "1 Chapter 1: Time Series Fundamentals 1.1 Definition 1.2 White Noise: purely random process 1.3 Random Walk: random but dependent 1.4 Time Series Properties 1.5 Stationarity", " 1 Chapter 1: Time Series Fundamentals 1.1 Definition \\[\\{X_t|t\\in T \\}\\] where \\(X_t\\) denotes random variables that are continuous, \\(T\\) denotes index sets that are discrete and equally spaced in time \\(x_t\\) denotes observations, or realisations of \\(X_t\\) 1.2 White Noise: purely random process \\[E[X_t]=\\mu\\] \\(Var[X_t]=\\sigma^2\\) where each \\(X_t\\) is independent It asssumes the observations are all independent 1.3 Random Walk: random but dependent \\[ X_T = X_{t-1} +Z_t\\] where \\(Z_t\\) is a purely random process with mean \\(\\mu\\) and variance \\(\\sigma^2\\) ## Time Series Modelling Time series data are often decomposed into the following three components: Trend, Seasonal Effect, Unexplained variation Data with additive structure is easier to analyze as compared to multiplicative structure. If the time series data has multiplicative structure, we can model it by using transformations. 1.3.1 Log Transformation \\[log(X_t)=log(m_t\\cdot s_t\\cdot e_t)=log(m_t)+log(s_t)+log(e_t)\\] Use to stablize variance, make seasonal effect \\(s_t\\) additive, &amp; make the data normally distributed. 1.3.2 Box-Cox Transformation \\[ y_t=(x_t^\\lambda-1)/\\lambda \\space\\space \\lambda\\ne0\\] \\[ or \\space y_t=ln(x_t) \\space\\space \\lambda=0\\] where \\(\\lambda\\) is a tuning parameter chosen by the analyst 1.4 Time Series Properties 1.4.1 Mean function (if mean is constant) \\[\\mu_t=E[X_t]\\] \\[\\hat \\mu=\\frac 1n\\sum_{t=1}^{n}x_t\\] In case of walking average, see ch.2 1.4.2 Variance function (if variance is constant) \\[\\sigma_t^2=Var[X_t]=E[X_t^2]-E[X_t]^2\\] \\[\\hat \\sigma^2=\\frac1{n-1} \\sum_{t=1}^n{(x_t-\\hat\\mu)^2}\\] 1.4.3 Autocovariance function (ACVF): \\[\\gamma_{s,t}=Cov[X_s,X_t]=E[X_sX_t]-E[X_t]E[X_s]\\] where \\(\\gamma_{t,t}=Cov[X_t,X_t]=Var[X_t]=\\sigma_t^2\\) Real data: \\[\\gamma_\\tau=Cov[X_tX_{t+\\tau}]\\] with lag \\(\\tau=0,1,2,..\\) 1.4.4 Autocorrelation function (ACF): \\[\\rho_{s,t}=Corr[X_s,X_t]=\\frac{Cov[X_s,X_t]}{\\sqrt{Var[X_s]Var[X_t]}}=\\frac{\\gamma_{s,t}}{\\sigma_s\\sigma_t}\\] where \\(\\rho_{t,t}=Corr[X_t,X_t]=1\\) Real data: \\[\\rho_\\tau=Corr[X_tX_{t+\\tau}]=\\frac{Cov[X_t,X_{t+\\tau}]}{\\sqrt{Var[X_t]Var[X_{t+\\tau}]}}=\\frac{\\gamma_\\tau}{\\gamma_0}\\] 1.4.5 Properties Property 1: \\(\\rho_\\tau=\\rho_{-\\tau}\\) Property 2: \\(|\\rho_\\tau|\\leq1\\) Property 3: Invertibility is not assumed 1.5 Stationarity A time series process \\(\\{X_t|t\\in T\\}\\) is strictly stationary if the joint distribution \\(f(X_{t1},...,X_{tk})\\) is identical to the joint distribution \\(f(X_{t1+r},...,X_{tk+r})\\) for all collections \\(t_1,...,t_k\\) and separation values \\(r\\). In other words, shifting the time origin of the series by \\(r\\) has no effect on its joint distribution. A time series process \\(\\{X_t|t\\in T\\}\\) is weakly stationary (or second-order stationary) if 1, mean function is constant and finite; 2, variance function is constant and finite; 3, autocovariance and autocorrelation functions only depend on the lag. "],
["chapter-2-modelling-trends-and-seasonal-patterns.html", "2 Chapter 2: Modelling trends and seasonal patterns 2.1 Method 1: Regression 2.2 Method 2: Moving Average Smoothing 2.3 Method 3: Differencing 2.4 Choosing a smoothing parameter", " 2 Chapter 2: Modelling trends and seasonal patterns Trend and Seasonality can be the main interests Need to remove trend and seasonality to determine short-term correlation For this chapter, assume additivity: \\(X_t=m_t+s_t+e_t\\) (Refer to Ch.1) First is to estimate the trend and seasonal variation \\(\\hat m_t+\\hat s_t\\), then calculate the residual series \\(e_t^*=X_t-\\hat m_t-\\hat s_t\\) 3 of the most common methods for modelling trend and seasonality are described here. 2.1 Method 1: Regression \\[m_t+s_t=\\beta_0+\\beta_1z_{t1}+...+\\beta_pz_{tp}\\] Cons: OLS estimation assumes observations are independent. Pros: Remove trend to later model the correlation by a stationary time series process \\(z_{tn}\\) are often functions of time 2.1.1 Examples 2.1.1.1 Linear trend in time but no seasonal variation: Trend can be modelled by \\(X_t=\\beta_0+\\beta_1t+e_t\\) and using series \\(e_t\\) to analyze short-term correlation 2.1.1.2 Quadratic trend in time but no seasonal variation: Trend can be modeled by \\(X_t=\\beta_0+\\beta_1t+\\beta_2t^2+e_t\\) 2.1.1.3 Seasonal pattern in time and a linear trend with 365 data points: Trend and Seasonality can be modeled by \\(X_t=\\beta_0+\\beta_1t+\\beta_2sin(8\\pi t/365)+e_t\\) 2.1.2 Other common models 2.1.2.1 Other Covariates \\[m_t=\\beta+0+\\beta_1\\alpha_t\\] 2.1.2.2 Polynomials \\[m_t=\\beta+0+\\beta_1t+\\beta_qt^q\\] Higher \\(q\\), more flexible the trend 2.1.2.3 Harmonics \\[s_t=\\beta_0+\\sum_{i=1}^q\\beta_{1i}sin(w_it)+\\beta_{2i}cos(w_it)\\] Harmonics assume the seasonal pattern has a regular shape, i.e. the height of the peaks is the same as the depth of the troughs. 2.1.2.4 Seasonal Factors Assuming the seasonal pattern repeats itself every d time points, a less restrictive approach is to model it as: \\[s_{t}=\\left\\{\\begin{array}{cc}0&amp;\\mbox{if}~t=1, d+1, 2d+2,\\ldots\\\\ s_{2}&amp;\\mbox{if}~t=2, d+2, 2d+2,\\ldots\\\\ \\vdots&amp;\\vdots\\\\ s_{d}&amp;\\mbox{if}~t=d, 2d, 3d,\\ldots\\\\\\end{array}\\right.\\] This model can be fitted by creating \\(d - 1\\) dummy variables in the design matrix, that contain 1’s and 0’s. 2.1.2.5 Natural cubic splines (More flexible) \\[m_{t}+s_{t}=\\beta_{0}+\\sum_{i=1}^{q}\\beta_{i}B_{i}(t)\\] 2.2 Method 2: Moving Average Smoothing A Moving average smoother estimates the trend and seasonal variation at time t by averaging the current observation and the q either side \\[\\hat{m}_{t}+\\hat{s}_{t}=\\frac{1}{2q+1}\\sum_{j=-q}^{q}x_{t-j}\\] Note: Shorten length of time series by \\(2q\\), therefore if the trend is smooth and \\(q\\) is large, the series shortens significantly. 2.3 Method 3: Differencing 2.3.1 Remove Trends 2.3.1.1 First order difference operator \\(\\nabla\\): \\[\\nabla X_{t}=X_{t}-X_{t-1}=(1-B)X_{t}\\] where \\(B\\) is the Backshift operator defined as \\(BX_{t}=X_{t-1}\\) 2.3.1.2 General order difference operator \\(\\nabla^q\\) \\[\\nabla^{q} X_{t}=\\nabla[\\nabla^{q-1}X_{t}]\\] \\[B^{q}X_{t}=X_{t-q}\\] Notes: 1. A polynomial trend of order \\(q\\) can be removed by \\(q^{th}\\) order differencing 2. Typically only first or second order differencing is required 3. Shortens length by \\(q\\) 4. Differencing won’t allow to estimate the trend but only to remove it. 2.3.2 Remove Seasonality The seasonal difference of order \\(d\\) is the operator \\(\\nabla_d\\) given by \\[\\nabla_{d} X_{t}=X_{t}-X_{t-d}=(1-B^{d})X_{t}\\] Notes: 1. Trial and Error approach 2. No point differencing twice if once is adequate 3. Differencing increases the variance 2.4 Choosing a smoothing parameter 2.4.1 Simplicity Simple statistical models are preferred since they are easier to make inferences from. 2.4.2 Objective criteria (AIC &amp; BIC) Assumptions: 1. Normally distributed observations 2. \\(m_{t}+s_{t}=\\textbf{z}_{t}^\\top \\boldsymbol{\\beta}\\) where \\(\\textbf{z}_{t}^\\top\\) is a vector of \\(q-1\\) known covariates and a one to represent the intercept term 2.4.2.1 Akaike’s Information Criterion (AIC) \\[\\mbox{AIC}(q)=-2\\mathcal{L}(\\mathbf{x}|\\hat{\\boldsymbol{\\beta}}) + 2q\\] 2.4.2.2 Bayesian Information Criterion (BIC) \\[\\mbox{BIC}(q)=-2\\mathcal{L}(\\mathbf{x}|\\hat{\\boldsymbol{\\beta}}) + \\ln(n)q\\] where \\(\\mathcal{L}(\\mathbf{x}|\\hat{\\boldsymbol{\\beta}})\\) is the maximised log likelihood function of \\(\\mathbf{x}\\) Both criteria tradeoff the fit to the data against simplicity (i.e. few parameters), and small values suggest a good fit to the data. "],
["references.html", "References", " References Time Series Fundamentals https://bookdown.org/gary_a_napier/time_series_lecture_notes/ChapterOne.html "]
]
